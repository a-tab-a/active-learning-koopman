{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd.gradcheck import zero_gradients\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jacobian(inputs, output, create_graph=False):\n",
    "    \"\"\"\n",
    "    :param inputs: Batch X Size (e.g. Depth X Width X Height)\n",
    "    :param output: Batch X Classes\n",
    "    :return: jacobian: Batch X Classes X Size\n",
    "    \"\"\"\n",
    "    assert inputs.requires_grad\n",
    "\n",
    "    num_classes = output.size()[1]\n",
    "\n",
    "    jacobian = torch.zeros(num_classes, *inputs.size())\n",
    "    grad_output = torch.zeros(*output.size())\n",
    "    if inputs.is_cuda:\n",
    "        grad_output = grad_output.cuda()\n",
    "        jacobian = jacobian.cuda()\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        zero_gradients(inputs)\n",
    "        grad_output.zero_()\n",
    "        grad_output[:, i] = 1\n",
    "        output.backward(grad_output, retain_graph=True, create_graph=create_graph)\n",
    "        jacobian[i] = inputs.grad\n",
    "\n",
    "    return torch.transpose(jacobian, dim0=0, dim1=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(10,2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9794, 0.0000],\n",
       "         [0.0000, 0.6740]],\n",
       "\n",
       "        [[0.8643, 0.0000],\n",
       "         [0.0000, 0.9522]],\n",
       "\n",
       "        [[0.7710, 0.0000],\n",
       "         [0.0000, 0.8072]],\n",
       "\n",
       "        [[0.9348, 0.0000],\n",
       "         [0.0000, 0.6828]],\n",
       "\n",
       "        [[0.9357, 0.0000],\n",
       "         [0.0000, 0.9813]],\n",
       "\n",
       "        [[0.8325, 0.0000],\n",
       "         [0.0000, 0.9660]],\n",
       "\n",
       "        [[0.9882, 0.0000],\n",
       "         [0.0000, 0.9721]],\n",
       "\n",
       "        [[0.9498, 0.0000],\n",
       "         [0.0000, 0.8743]],\n",
       "\n",
       "        [[0.9855, 0.0000],\n",
       "         [0.0000, 0.8856]],\n",
       "\n",
       "        [[0.9270, 0.0000],\n",
       "         [0.0000, 0.5811]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_jacobian(x, y, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
